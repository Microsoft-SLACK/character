labnotebook
===========

Output from training models used in future_work

In [2]: run reproduce_character_models optimize_fifty_years
There are 3000 volumes described in metadata.
Of those, 0 were missing in the directory.
80918 volumes in the directory were missing in metadata.
There were also 0 volumes excluded from the model by *excludeif*.

We have 1500 positive, and
1500 negative instances.

The whole corpus involved here includes 3000
volumes, ranging in date from 1780 to 1849.

The set of volumes not to be trained on includes 0
positive volumes, ranging from 3000 to 0.

And also includes 0
negative volumes, ranging from 3000 to 0.


Number of features 2700
Training positives: 1500
Training negatives: 1500
3000
compare
3000
[125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125]
[125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125]
variablecount: 2450  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7623333333333333

variablecount: 2500  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.767

variablecount: 2550  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.767

variablecount: 2600  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7663333333333333

variablecount: 2650  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.767

(1, 0)
2500 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

True positives 1129
True negatives 1172
False positives 328
False negatives 371
F1 : 0.7636117686844776
0.767 0.767
If we divide the dataset with a horizontal line at 0.5, accuracy is:  0.767
Divided with a line fit to the data trend, it's  0.765333333333

In [3]: run reproduce_character_models optimize_fifty_years
There are 3000 volumes described in metadata.
Of those, 2 were missing in the directory.
80920 volumes in the directory were missing in metadata.
There were also 0 volumes excluded from the model by *excludeif*.

We have 1500 positive, and
1498 negative instances.

The whole corpus involved here includes 2998
volumes, ranging in date from 1850 to 1899.

The set of volumes not to be trained on includes 0
positive volumes, ranging from 3000 to 0.

And also includes 0
negative volumes, ranging from 3000 to 0.


Number of features 2700
Training positives: 1500
Training negatives: 1498
2998
compare
2998
[125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 124, 124]
[125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125]
variablecount: 2450  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7698465643762509

variablecount: 2500  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7681787858572382

variablecount: 2550  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7708472314876584

variablecount: 2600  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7695130086724483

variablecount: 2650  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7658438959306204

(2, 0)
2550 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

True positives 1154
True negatives 1157
False positives 341
False negatives 346
F1 : 0.770617696160267
0.7708472314876584 0.770847231488
If we divide the dataset with a horizontal line at 0.5, accuracy is:  0.770847231488
Divided with a line fit to the data trend, it's  0.768512341561

In [4]: run reproduce_character_models optimize_fifty_years
There are 3000 volumes described in metadata.
Of those, 0 were missing in the directory.
80918 volumes in the directory were missing in metadata.
There were also 0 volumes excluded from the model by *excludeif*.

We have 1500 positive, and
1500 negative instances.

The whole corpus involved here includes 3000
volumes, ranging in date from 1900 to 1948.

The set of volumes not to be trained on includes 0
positive volumes, ranging from 3000 to 0.

And also includes 0
negative volumes, ranging from 3000 to 0.


Number of features 2700
Training positives: 1500
Training negatives: 1500
3000
compare
3000
[125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125]
[125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125]
variablecount: 2450  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7413333333333333

variablecount: 2500  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7413333333333333

variablecount: 2550  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7436666666666667

variablecount: 2600  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7426666666666667

variablecount: 2650  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7436666666666667

(2, 0)
2550 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

True positives 1130
True negatives 1101
False positives 399
False negatives 370
F1 : 0.7461208319577419
0.7436666666666667 0.743666666667
If we divide the dataset with a horizontal line at 0.5, accuracy is:  0.743666666667
Divided with a line fit to the data trend, it's  0.745333333333

In [5]: run reproduce_character_models optimize_fifty_years
There are 3000 volumes described in metadata.
Of those, 0 were missing in the directory.
80918 volumes in the directory were missing in metadata.
There were also 0 volumes excluded from the model by *excludeif*.

We have 1500 positive, and
1500 negative instances.

The whole corpus involved here includes 3000
volumes, ranging in date from 1950 to 2007.

The set of volumes not to be trained on includes 0
positive volumes, ranging from 3000 to 0.

And also includes 0
negative volumes, ranging from 3000 to 0.


Number of features 2700
Training positives: 1500
Training negatives: 1500
3000
compare
3000
[125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125]
[125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125, 125]
variablecount: 2450  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.703

variablecount: 2500  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7003333333333334

variablecount: 2550  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.6973333333333334

variablecount: 2600  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.6986666666666667

variablecount: 2650  regularization: 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

Accuracy: 0.7003333333333334

(0, 0)
2450 0.0001
Beginning multiprocessing.
Multiprocessing concluded.

True positives 1035
True negatives 1074
False positives 426
False negatives 465
F1 : 0.6990881458966566
0.703 0.703
If we divide the dataset with a horizontal line at 0.5, accuracy is:  0.703
Divided with a line fit to the data trend, it's  0.704333333333